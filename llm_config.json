{
    "openai-paid-gpt-5-nano": {
        "comment": "This is slow. It's paid, and requires that you have a OPENAI_API_KEY in the .env file. This is a reasoning model, so it takes MUCH longer to create a plan.",
        "priority": 3,
        "class": "OpenAI",
        "arguments": {
            "model": "gpt-5-nano",
            "api_key": "${OPENAI_API_KEY}",
            "temperature": 1.0,
            "timeout": 120.0,
            "reasoning_effort": "minimal",
            "context_window": 400000,
            "is_function_calling_model": false,
            "is_chat_model": true,
            "max_tokens": 128000,
            "max_retries": 5
        }
    },
    "openrouter-paid-openai-gpt-oss-20b": {
        "comment": "This is very fast. It's paid, so check the pricing before use. Created August 5, 2025. 131,072 context. $0.05/M input tokens. $0.20/M output tokens. This is a reasoning model, and uses more tokens than LLMs. Temperature must be 1.0 for reasoning models.",
        "priority": 7,
        "class": "OpenRouter",
        "arguments": {
            "model": "openai/gpt-oss-20b",
            "api_key": "${OPENROUTER_API_KEY}",
            "temperature": 1.0,
            "timeout": 60.0,
            "is_function_calling_model": false,
            "is_chat_model": true,
            "max_tokens": 8192,
            "max_retries": 5
        }
    },
    "openrouter-paid-nvidia-nemotron-3-nano-30b-a3b": {
        "comment": "This is very fast. It's paid, so check the pricing before use. Created Dec 14, 2025. 262,144 context. $0.06/M input tokens. $0.24/M output tokens. This is a reasoning model, and uses more tokens than LLMs. Temperature must be 1.0 for reasoning models.",
        "priority": 2,
        "class": "OpenRouter",
        "arguments": {
            "model": "nvidia/nemotron-3-nano-30b-a3b",
            "api_key": "${OPENROUTER_API_KEY}",
            "reasoning_effort": "none",
            "temperature": 1.0,
            "timeout": 60.0,
            "is_function_calling_model": false,
            "is_chat_model": true,
            "max_tokens": 128000,
            "max_retries": 5
        }
    },
    "openrouter-free-nvidia-nemotron-3-nano-30b-a3b:free": {
        "comment": "Free slug of Nemotron 3 Nano via OpenRouter. Added Feb 1, 2026 for testing.",
        "priority": 1,
        "class": "OpenRouter",
        "arguments": {
            "model": "nvidia/nemotron-3-nano-30b-a3b:free",
            "api_key": "${OPENROUTER_API_KEY}",
            "temperature": 1.0,
            "timeout": 60.0,
            "reasoning_effort": "minimal",
            "is_function_calling_model": false,
            "is_chat_model": true,
            "max_tokens": 128000,
            "max_retries": 5
        }
    },
    "openrouter-paid-gemini-3-flash-preview": {
        "comment": "Gemini 3 Flash Preview - Very fast. It's paid, check the pricing before use. Current workhorse model.",
        "priority": 6,
        "class": "OpenRouter",
        "arguments": {
            "model": "google/gemini-3-flash-preview",
            "api_key": "${OPENROUTER_API_KEY}",
            "temperature": 0.1,
            "timeout": 60.0,
            "is_function_calling_model": false,
            "is_chat_model": true,
            "max_tokens": 128000,
            "max_retries": 5
        }
    },
    "openrouter-paid-z-ai-glm-4.7-flash": {
        "comment": "GLM-4.7 Flash - Fast model from Z-AI. It's paid, check pricing before use.",
        "priority": 3,
        "class": "OpenRouter",
        "arguments": {
            "model": "z-ai/glm-4.7-flash",
            "api_key": "${OPENROUTER_API_KEY}",
            "temperature": 0.1,
            "timeout": 60.0,
            "is_function_calling_model": false,
            "is_chat_model": true,
            "max_tokens": 128000,
            "max_retries": 5
        }
    },
    "openrouter-paid-z-ai-glm-4.7": {
        "comment": "GLM-4.7 - Standard model from Z-AI. It's paid, check pricing before use.",
        "priority": 4,
        "class": "OpenRouter",
        "arguments": {
            "model": "z-ai/glm-4.7",
            "api_key": "${OPENROUTER_API_KEY}",
            "temperature": 0.1,
            "timeout": 60.0,
            "is_function_calling_model": false,
            "is_chat_model": true,
            "max_tokens": 128000,
            "max_retries": 5
        }
    },
    "openrouter-paid-xiaomi-mimo-v2-flash": {
        "comment": "Mimo v2 Flash - Fast model from Xiaomi. It's paid, check pricing before use.",
        "priority": 5,
        "class": "OpenRouter",
        "arguments": {
            "model": "xiaomi/mimo-v2-flash",
            "api_key": "${OPENROUTER_API_KEY}",
            "temperature": 0.1,
            "timeout": 60.0,
            "is_function_calling_model": false,
            "is_chat_model": true,
            "max_tokens": 128000,
            "max_retries": 5
        }
    },
    "openrouter-free-trinity-large-preview": {
        "comment": "Free model from Arcee AI via OpenRouter. Updated Feb 1, 2026. Testing priority 1.",
        "priority": 11,
        "class": "OpenRouter",
        "arguments": {
            "model": "arcee-ai/trinity-large-preview:free",
            "api_key": "${OPENROUTER_API_KEY}",
            "temperature": 1.0,
            "timeout": 120.0,
            "is_function_calling_model": false,
            "is_chat_model": true,
            "max_tokens": 100000,
            "max_retries": 5
        }
    },
    "ollama-llama3.1": {
        "comment": "This runs on your own computer. It's free. Requires Ollama to be installed. PlanExe runs in .venv on the host computer. No use of docker.",
        "class": "Ollama",
        "arguments": {
            "model": "llama3.1:latest",
            "temperature": 0.5,
            "request_timeout": 120.0,
            "is_function_calling_model": false
        }
    },
    "docker-ollama-llama3.1": {
        "comment": "This runs on your own computer. It's free. Requires Ollama to be installed. PlanExe runs in a Docker container, and ollama is installed on the host the computer.",
        "class": "Ollama",
        "arguments": {
            "model": "llama3.1:latest",
            "base_url": "http://host.docker.internal:11434",
            "temperature": 0.5,
            "request_timeout": 120.0,
            "is_function_calling_model": false
        }
    },
    "ollama-qwen2.5-coder": {
        "comment": "This runs on your own computer. It's free. Requires Ollama to be installed. PlanExe runs in .venv on the host computer. No use of docker.",
        "class": "Ollama",
        "arguments": {
            "model": "qwen2.5-coder:latest",
            "temperature": 0.5,
            "request_timeout": 120.0,
            "is_function_calling_model": false
        }
    },
    "lmstudio-qwen2.5-7b-instruct-1m": {
        "comment": "This runs on your own computer. It's free. Requires LM Studio to be installed. Great for inspecting the request/response. PlanExe runs in .venv on the host computer. No use of docker.",
        "class": "LMStudio",
        "arguments": {
            "model_name": "qwen2.5-7b-instruct-1m",
            "base_url": "http://localhost:1234/v1",
            "temperature": 0.2,
            "request_timeout": 120.0,
            "is_function_calling_model": false
        }
    },
    "docker-lmstudio-qwen2.5-7b-instruct-1m": {
        "comment": "This runs on your own computer. It's free. Requires LM Studio to be installed. Great for inspecting the request/response. PlanExe runs in a Docker container, and ollama is installed on the host the computer.",
        "class": "LMStudio",
        "arguments": {
            "model_name": "qwen2.5-7b-instruct-1m",
            "base_url": "http://host.docker.internal:1234/v1",
            "temperature": 0.2,
            "request_timeout": 120.0,
            "is_function_calling_model": false
        }
    }
}