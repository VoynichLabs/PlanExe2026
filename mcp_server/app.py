"""
PlanExe MCP Server

Implements the Model Context Protocol interface for PlanExe as specified in
extra/mcp-spec1.md. Communicates with worker_plan_database via the shared
database_api models.
"""
import asyncio
import hashlib
import io
import json
import logging
import os
import sys
import uuid
import zipfile
from datetime import UTC, datetime
from pathlib import Path
from typing import Any, Optional
from urllib.parse import quote_plus
from io import BytesIO
import httpx
from sqlalchemy import cast, inspect, text
from sqlalchemy.dialects.postgresql import JSONB
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import CallToolResult, Tool, TextContent
from pydantic import BaseModel

# Load .env file early
from mcp_server.dotenv_utils import load_planexe_dotenv
_dotenv_loaded, _dotenv_paths = load_planexe_dotenv(Path(__file__).parent)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
if not _dotenv_loaded:
    logger.warning(
        "No .env file found; searched: %s",
        ", ".join(str(path) for path in _dotenv_paths),
    )

# Database imports
from database_api.planexe_db_singleton import db
from database_api.model_taskitem import TaskItem, TaskState
from database_api.model_event import EventItem, EventType
from flask import Flask, has_app_context

# Initialize Flask app for database access
app = Flask(__name__)
app.config.from_pyfile('config.py')

def build_postgres_uri_from_env(env: dict[str, str]) -> tuple[str, dict[str, str]]:
    """Construct a SQLAlchemy URI for Postgres using environment variables."""
    host = env.get("PLANEXE_POSTGRES_HOST") or "database_postgres"
    port = str(env.get("PLANEXE_POSTGRES_PORT") or "5432")
    dbname = env.get("PLANEXE_POSTGRES_DB") or "planexe"
    user = env.get("PLANEXE_POSTGRES_USER") or "planexe"
    password = env.get("PLANEXE_POSTGRES_PASSWORD") or "planexe"
    uri = f"postgresql+psycopg2://{quote_plus(user)}:{quote_plus(password)}@{host}:{port}/{dbname}"
    safe_config = {"host": host, "port": port, "dbname": dbname, "user": user}
    return uri, safe_config

# Load database configuration
sqlalchemy_database_uri = os.environ.get("SQLALCHEMY_DATABASE_URI")
if sqlalchemy_database_uri is None:
    sqlalchemy_database_uri, db_settings = build_postgres_uri_from_env(os.environ)
    logger.info(f"SQLALCHEMY_DATABASE_URI not set. Using Postgres defaults: {db_settings}")
else:
    logger.info("Using SQLALCHEMY_DATABASE_URI from environment.")

app.config['SQLALCHEMY_DATABASE_URI'] = sqlalchemy_database_uri
app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {'pool_recycle': 280, 'pool_pre_ping': True}
db.init_app(app)

def ensure_taskitem_stop_columns() -> None:
    insp = inspect(db.engine)
    columns = {col["name"] for col in insp.get_columns("task_item")}
    with db.engine.begin() as conn:
        if "stop_requested" not in columns:
            conn.execute(text("ALTER TABLE task_item ADD COLUMN IF NOT EXISTS stop_requested BOOLEAN"))
        if "stop_requested_timestamp" not in columns:
            conn.execute(text("ALTER TABLE task_item ADD COLUMN IF NOT EXISTS stop_requested_timestamp TIMESTAMP"))

with app.app_context():
    ensure_taskitem_stop_columns()

# MCP Server setup
mcp_server = Server("planexe-mcp-server")

# Base directory for run artifacts (not used directly, fetched via worker_plan HTTP API)
BASE_DIR_RUN = Path(os.environ.get("PLANEXE_RUN_DIR", Path(__file__).parent.parent / "run")).resolve()

# Worker plan HTTP API URL
WORKER_PLAN_URL = os.environ.get("PLANEXE_WORKER_PLAN_URL", "http://worker_plan:8000")

REPORT_FILENAME = "030-report.html"
REPORT_READ_DEFAULT_BYTES = 200_000
REPORT_READ_MAX_BYTES = 1_000_000
REPORT_CONTENT_TYPE = "text/html; charset=utf-8"

SPEED_VS_DETAIL_DEFAULT = "ping_llm"
SPEED_VS_DETAIL_VALUES = (
    "ping_llm",
    "fast_but_skip_details",
    "all_details_but_slow",
)
SPEED_VS_DETAIL_ALIASES = {
    "fast": "fast_but_skip_details",
    "all": "all_details_but_slow",
    "ping": "ping_llm",
}

# Pydantic models for request/response validation
class SessionCreateRequest(BaseModel):
    idea: str
    config: Optional[dict[str, Any]] = None
    metadata: Optional[dict[str, Any]] = None

class SessionStartRequest(BaseModel):
    session_id: str
    target: str = "build_plan_and_validate"
    inputs: Optional[dict[str, Any]] = None

class SessionStatusRequest(BaseModel):
    session_id: str

class SessionStopRequest(BaseModel):
    session_id: str
    run_id: Optional[str] = None
    mode: str = "graceful"

class SessionResumeRequest(BaseModel):
    session_id: str
    target: str = "build_plan_and_validate"
    resume_policy: str = "luigi_up_to_date"
    invalidate: Optional[dict[str, Any]] = None

class ArtifactListRequest(BaseModel):
    session_id: str
    path: str = ""
    include_metadata: bool = True

class ArtifactReadRequest(BaseModel):
    artifact_uri: str
    range: Optional[dict[str, int]] = None

class ReportReadRequest(BaseModel):
    session_id: str
    range: Optional[dict[str, int]] = None

class ArtifactWriteRequest(BaseModel):
    artifact_uri: str
    content: str
    edit_reason: Optional[str] = None
    lock: Optional[dict[str, str]] = None

class SessionEventsRequest(BaseModel):
    session_id: str
    since: Optional[str] = None

# Helper functions
def find_task_by_session_id(session_id: str) -> Optional[TaskItem]:
    """Find TaskItem by session_id stored in parameters."""
    def _query() -> Optional[TaskItem]:
        query = db.session.query(TaskItem)
        if db.engine.dialect.name == "postgresql":
            tasks = query.filter(
                cast(TaskItem.parameters, JSONB).contains({"_mcp_session_id": session_id})
            ).all()
        else:
            tasks = query.filter(
                TaskItem.parameters.contains({"_mcp_session_id": session_id})
            ).all()
        if tasks:
            return tasks[0]
        return None

    if has_app_context():
        return _query()
    with app.app_context():
        return _query()

def get_task_id_for_session(session_id: str) -> Optional[str]:
    """Get the task_id (run_id) for a session."""
    task = find_task_by_session_id(session_id)
    if task:
        return str(task.id)
    # Fallback: try parsing session_id format
    if "__" in session_id:
        # Extract UUID portion from pxe_YYYY_MM_DD__{uuid}
        uuid_part = session_id.split("__", 1)[1]
        # Try to find task by UUID
        try:
            task_id = uuid.UUID(uuid_part)
            return str(task_id)
        except ValueError:
            pass
    return None

def get_task_by_id(task_id: str) -> Optional[TaskItem]:
    """Fetch a TaskItem by its UUID string."""
    def _query() -> Optional[TaskItem]:
        try:
            task_uuid = uuid.UUID(task_id)
        except ValueError:
            return None
        return db.session.get(TaskItem, task_uuid)

    if has_app_context():
        return _query()
    with app.app_context():
        return _query()

def resolve_task_for_session(session_id: str) -> Optional[TaskItem]:
    """Resolve a TaskItem from a session_id, with UUID fallback."""
    task = find_task_by_session_id(session_id)
    if task is not None:
        return task
    if "__" not in session_id:
        return None
    uuid_part = session_id.split("__", 1)[1]
    try:
        uuid.UUID(uuid_part)
    except ValueError:
        return None
    return get_task_by_id(uuid_part)

def list_files_from_zip_bytes(zip_bytes: bytes) -> list[str]:
    """List file entries from an in-memory zip archive."""
    try:
        with zipfile.ZipFile(BytesIO(zip_bytes), 'r') as zip_file:
            files = [name for name in zip_file.namelist() if not name.endswith("/")]
            return sorted(files)
    except Exception as exc:
        logger.warning("Unable to list files from zip snapshot: %s", exc)
        return []

def extract_file_from_zip_bytes(zip_bytes: bytes, file_path: str) -> Optional[bytes]:
    """Extract a file from an in-memory zip archive."""
    try:
        with zipfile.ZipFile(BytesIO(zip_bytes), 'r') as zip_file:
            file_path_normalized = file_path.lstrip('/')
            try:
                return zip_file.read(file_path_normalized)
            except KeyError:
                return None
    except Exception as exc:
        logger.warning("Unable to read %s from zip snapshot: %s", file_path, exc)
        return None

def fetch_report_from_db(task_id: str) -> Optional[bytes]:
    """Fetch the report HTML stored in the TaskItem."""
    task = get_task_by_id(task_id)
    if task and task.generated_report_html is not None:
        return task.generated_report_html.encode("utf-8")
    return None

def fetch_file_from_zip_snapshot(task_id: str, file_path: str) -> Optional[bytes]:
    """Fetch a file from the TaskItem zip snapshot."""
    task = get_task_by_id(task_id)
    if task and task.run_zip_snapshot is not None:
        return extract_file_from_zip_bytes(task.run_zip_snapshot, file_path)
    return None

def list_files_from_zip_snapshot(task_id: str) -> Optional[list[str]]:
    """List files from the TaskItem zip snapshot."""
    task = get_task_by_id(task_id)
    if task and task.run_zip_snapshot is not None:
        return list_files_from_zip_bytes(task.run_zip_snapshot)
    return None

async def fetch_artifact_from_worker_plan(run_id: str, file_path: str) -> Optional[bytes]:
    """Fetch an artifact file from worker_plan via HTTP."""
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            # For report.html, use the dedicated report endpoint (most efficient)
            if (
                file_path == "report.html"
                or file_path.endswith("/report.html")
                or file_path == REPORT_FILENAME
                or file_path.endswith(f"/{REPORT_FILENAME}")
            ):
                report_response = await client.get(f"{WORKER_PLAN_URL}/runs/{run_id}/report")
                if report_response.status_code == 200:
                    return report_response.content
                logger.warning(f"Worker plan returned {report_response.status_code} for report: {run_id}")
                report_from_db = fetch_report_from_db(run_id)
                if report_from_db is not None:
                    return report_from_db
                report_from_zip = fetch_file_from_zip_snapshot(run_id, REPORT_FILENAME)
                if report_from_zip is not None:
                    return report_from_zip
                return None
            
            # For other files, fetch the zip and extract the file
            # This is less efficient but works without a file serving endpoint
            zip_response = await client.get(f"{WORKER_PLAN_URL}/runs/{run_id}/zip")
            if zip_response.status_code != 200:
                logger.warning(f"Worker plan returned {zip_response.status_code} for zip: {run_id}")
            else:
                # Extract the file from the zip in memory
                zip_bytes = zip_response.content
                file_data = extract_file_from_zip_bytes(zip_bytes, file_path)
                if file_data is not None:
                    return file_data
            
            snapshot_file = fetch_file_from_zip_snapshot(run_id, file_path)
            if snapshot_file is not None:
                return snapshot_file
            return None
            
    except Exception as e:
        logger.error(f"Error fetching artifact from worker_plan: {e}", exc_info=True)
        return None

async def fetch_file_list_from_worker_plan(run_id: str) -> Optional[list[str]]:
    """Fetch the list of files from worker_plan via HTTP."""
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(f"{WORKER_PLAN_URL}/runs/{run_id}/files")
            if response.status_code == 200:
                data = response.json()
                return data.get("files", [])
            logger.warning(f"Worker plan returned {response.status_code} for files list: {run_id}")
            fallback_files = list_files_from_zip_snapshot(run_id)
            if fallback_files is not None:
                return fallback_files
            return None
    except Exception as e:
        logger.error(f"Error fetching file list from worker_plan: {e}", exc_info=True)
        return None

def compute_sha256(content: str | bytes) -> str:
    """Compute SHA256 hash of content."""
    if isinstance(content, str):
        content = content.encode('utf-8')
    return hashlib.sha256(content).hexdigest()

def get_task_state_mapping(task_state: TaskState) -> str:
    """Map TaskState to MCP run state."""
    mapping = {
        TaskState.pending: "stopped",
        TaskState.processing: "running",
        TaskState.completed: "completed",
        TaskState.failed: "failed",
    }
    return mapping.get(task_state, "stopped")

def resolve_speed_vs_detail(config: Optional[dict[str, Any]]) -> str:
    value: Optional[str] = None
    if isinstance(config, dict):
        raw_value = config.get("speed_vs_detail") or config.get("speed")
        if isinstance(raw_value, str):
            value = raw_value.strip().lower()
    if value in SPEED_VS_DETAIL_ALIASES:
        return SPEED_VS_DETAIL_ALIASES[value]
    if value in SPEED_VS_DETAIL_VALUES:
        return value
    return SPEED_VS_DETAIL_DEFAULT

def build_report_artifact_uri(session_id: str) -> str:
    return f"planexe://sessions/{session_id}/out/{REPORT_FILENAME}"

def build_report_download_path(session_id: str) -> str:
    return f"/download/{session_id}/{REPORT_FILENAME}"

def build_report_download_url(session_id: str) -> Optional[str]:
    base_url = os.environ.get("PLANEXE_MCP_PUBLIC_BASE_URL")
    if not base_url:
        return None
    return f"{base_url.rstrip('/')}{build_report_download_path(session_id)}"

# Output schemas for MCP tools.
ERROR_SCHEMA = {
    "type": "object",
    "properties": {
        "code": {"type": "string"},
        "message": {"type": "string"},
    },
    "required": ["code", "message"],
}
SESSION_CREATE_OUTPUT_SCHEMA = {
    "type": "object",
    "properties": {
        "session_id": {"type": "string"},
        "output_dir_uri": {"type": "string"},
        "created_at": {"type": "string"},
    },
    "required": ["session_id", "output_dir_uri", "created_at"],
}
SESSION_STATUS_OUTPUT_SCHEMA = {
    "oneOf": [
        {
            "type": "object",
            "properties": {"error": ERROR_SCHEMA},
            "required": ["error"],
        },
        {
            "type": "object",
            "properties": {
                "session_id": {"type": "string"},
                "run_id": {"type": ["string", "null"]},
                "state": {
                    "type": "string",
                    "enum": ["stopped", "running", "completed", "failed", "stopping"],
                },
                "phase": {
                    "type": "string",
                    "enum": [
                        "initializing",
                        "generating_plan",
                        "validating",
                        "exporting",
                        "finalizing",
                    ],
                },
                "progress": {
                    "type": "object",
                    "properties": {
                        "overall": {"type": "number"},
                        "current_task": {
                            "type": "object",
                            "properties": {
                                "name": {"type": "string"},
                                "pct": {"type": "number"},
                            },
                            "required": ["name", "pct"],
                        },
                    },
                    "required": ["overall", "current_task"],
                },
                "timing": {
                    "type": "object",
                    "properties": {
                        "started_at": {"type": ["string", "null"]},
                        "elapsed_sec": {"type": "number"},
                    },
                    "required": ["started_at", "elapsed_sec"],
                },
                "latest_artifacts": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "path": {"type": "string"},
                            "artifact_uri": {"type": "string"},
                            "kind": {"type": "string"},
                            "updated_at": {"type": "string"},
                        },
                        "required": ["path", "artifact_uri", "kind", "updated_at"],
                    },
                },
                "warnings": {"type": "array", "items": {"type": "string"}},
            },
            "required": [
                "session_id",
                "run_id",
                "state",
                "phase",
                "progress",
                "timing",
                "latest_artifacts",
                "warnings",
            ],
        },
    ]
}
REPORT_RANGE_SCHEMA = {
    "type": "object",
    "properties": {
        "start": {"type": "integer", "minimum": 0},
        "length": {"type": "integer", "minimum": 0},
    },
    "required": ["start", "length"],
}
REPORT_READY_OUTPUT_SCHEMA = {
    "type": "object",
    "properties": {
        "state": {"const": "ready"},
        "artifact_uri": {"type": "string"},
        "content_type": {"type": "string"},
        "sha256": {"type": "string"},
        "download_path": {"type": "string"},
        "download_size": {"type": "integer"},
        "download_url": {"type": "string"},
        "content": {"type": "string"},
        "total_size": {"type": "integer"},
        "range": REPORT_RANGE_SCHEMA,
        "truncated": {"type": "boolean"},
        "next_range": REPORT_RANGE_SCHEMA,
    },
    "required": [
        "state",
        "artifact_uri",
        "content_type",
        "sha256",
        "download_path",
        "download_size",
    ],
}
REPORT_RESULT_OUTPUT_SCHEMA = {
    "oneOf": [
        {
            "type": "object",
            "properties": {"error": ERROR_SCHEMA},
            "required": ["error"],
        },
        {
            "type": "object",
            "properties": {"state": {"const": "running"}},
            "required": ["state"],
        },
        {
            "type": "object",
            "properties": {"state": {"const": "failed"}, "error": ERROR_SCHEMA},
            "required": ["state", "error"],
        },
        REPORT_READY_OUTPUT_SCHEMA,
    ]
}

# MCP Tool implementations
@mcp_server.list_tools()
async def handle_list_tools() -> list[Tool]:
    """List all available MCP tools."""
    return [
        Tool(
            name="planexe.session.create",
            description="Creates a new session and output namespace",
            outputSchema=SESSION_CREATE_OUTPUT_SCHEMA,
            inputSchema={
                "type": "object",
                "properties": {
                    "idea": {"type": "string", "description": "The idea/prompt for the plan"},
                    "config": {
                        "type": "object",
                        "description": "Optional configuration",
                        "properties": {
                            "speed_vs_detail": {
                                "type": "string",
                                "enum": list(SPEED_VS_DETAIL_VALUES),
                                "description": (
                                    "Defaults to ping_llm. Aliases: fast -> fast_but_skip_details, "
                                    "all -> all_details_but_slow."
                                ),
                            }
                        },
                        "additionalProperties": True,
                    },
                    "metadata": {"type": "object", "description": "Optional metadata including user_id"},
                },
                "required": ["idea"],
            },
        ),
        Tool(
            name="planexe.session.start",
            description="Starts execution for a target DAG output",
            inputSchema={
                "type": "object",
                "properties": {
                    "session_id": {"type": "string"},
                    "target": {"type": "string", "default": "build_plan_and_validate"},
                    "inputs": {"type": "object"},
                },
                "required": ["session_id"],
            },
        ),
        Tool(
            name="planexe.session.status",
            description="Returns run status and progress",
            outputSchema=SESSION_STATUS_OUTPUT_SCHEMA,
            inputSchema={
                "type": "object",
                "properties": {
                    "session_id": {"type": "string"},
                },
                "required": ["session_id"],
            },
        ),
        Tool(
            name="planexe.session.stop",
            description="Stops the active run",
            inputSchema={
                "type": "object",
                "properties": {
                    "session_id": {"type": "string"},
                    "run_id": {"type": "string"},
                    "mode": {"type": "string", "default": "graceful"},
                },
                "required": ["session_id"],
            },
        ),
        Tool(
            name="planexe.session.resume",
            description="Resumes execution, reusing cached Luigi outputs",
            inputSchema={
                "type": "object",
                "properties": {
                    "session_id": {"type": "string"},
                    "target": {"type": "string", "default": "build_plan_and_validate"},
                    "resume_policy": {"type": "string", "default": "luigi_up_to_date"},
                    "invalidate": {"type": "object"},
                },
                "required": ["session_id"],
            },
        ),
        Tool(
            name="planexe.artifact.list",
            description="Lists artifacts under output namespace",
            inputSchema={
                "type": "object",
                "properties": {
                    "session_id": {"type": "string"},
                    "path": {"type": "string", "default": ""},
                    "include_metadata": {"type": "boolean", "default": True},
                },
                "required": ["session_id"],
            },
        ),
        Tool(
            name="planexe.artifact.read",
            description="Reads an artifact",
            inputSchema={
                "type": "object",
                "properties": {
                    "artifact_uri": {"type": "string"},
                    "range": {"type": "object"},
                },
                "required": ["artifact_uri"],
            },
        ),
        Tool(
            name="planexe.report.read",
            description="Returns download metadata for the generated report (optional chunked fallback via range)",
            inputSchema={
                "type": "object",
                "properties": {
                    "session_id": {"type": "string"},
                    "range": {
                        "type": "object",
                        "description": "Optional byte range for chunked fallback. Defaults to first 200k bytes, max 1MB.",
                    },
                },
                "required": ["session_id"],
            },
        ),
        Tool(
            name="planexe.get.result",
            description="Returns download metadata for the generated report",
            outputSchema=REPORT_RESULT_OUTPUT_SCHEMA,
            inputSchema={
                "type": "object",
                "properties": {
                    "session_id": {"type": "string"},
                },
                "required": ["session_id"],
            },
        ),
        Tool(
            name="planexe.artifact.write",
            description="Writes an artifact (enables Stop → Edit → Resume)",
            inputSchema={
                "type": "object",
                "properties": {
                    "artifact_uri": {"type": "string"},
                    "content": {"type": "string"},
                    "edit_reason": {"type": "string"},
                    "lock": {"type": "object"},
                },
                "required": ["artifact_uri", "content"],
            },
        ),
        Tool(
            name="planexe.session.events",
            description="Provides incremental events for a session since a cursor",
            inputSchema={
                "type": "object",
                "properties": {
                    "session_id": {"type": "string"},
                    "since": {"type": "string"},
                },
                "required": ["session_id"],
            },
        ),
    ]

@mcp_server.call_tool()
async def handle_call_tool(name: str, arguments: dict[str, Any]) -> list[TextContent]:
    """Handle tool calls."""
    try:
        if name == "planexe.session.create":
            return await handle_session_create(arguments)
        elif name == "planexe.session.start":
            return await handle_session_start(arguments)
        elif name == "planexe.session.status":
            return await handle_session_status(arguments)
        elif name == "planexe.session.stop":
            return await handle_session_stop(arguments)
        elif name == "planexe.session.resume":
            return await handle_session_resume(arguments)
        elif name == "planexe.artifact.list":
            return await handle_artifact_list(arguments)
        elif name == "planexe.artifact.read":
            return await handle_artifact_read(arguments)
        elif name == "planexe.report.read":
            return await handle_report_read(arguments)
        elif name == "planexe.get.result":
            return await handle_report_read(arguments)
        elif name == "planexe.artifact.write":
            return await handle_artifact_write(arguments)
        elif name == "planexe.session.events":
            return await handle_session_events(arguments)
        else:
            return [TextContent(
                type="text",
                text=json.dumps({"error": {"code": "INVALID_TOOL", "message": f"Unknown tool: {name}"}})
            )]
    except Exception as e:
        logger.error(f"Error handling tool {name}: {e}", exc_info=True)
        return [TextContent(
            type="text",
            text=json.dumps({"error": {"code": "INTERNAL_ERROR", "message": str(e)}})
        )]

async def handle_session_create(arguments: dict[str, Any]) -> CallToolResult:
    """Handle planexe.session.create"""
    req = SessionCreateRequest(**arguments)
    
    with app.app_context():
        parameters = dict(req.config or {})
        parameters["speed_vs_detail"] = resolve_speed_vs_detail(parameters)

        # Create a new TaskItem (which represents a session in our model)
        task = TaskItem(
            prompt=req.idea,
            state=TaskState.pending,
            user_id=req.metadata.get("user_id", "mcp_user") if req.metadata else "mcp_user",
            parameters=parameters,
        )
        db.session.add(task)
        db.session.commit()
        
        # Generate session_id in format: pxe_{date}__{short_uuid}
        date_str = datetime.now(UTC).strftime("%Y_%m_%d")
        short_uuid = str(task.id).replace("-", "")[:8]
        session_id = f"pxe_{date_str}__{short_uuid}"
        output_dir_uri = f"planexe://sessions/{session_id}/out"
        
        # Store session_id mapping in task parameters for later lookup
        parameters = dict(task.parameters or {})
        parameters["_mcp_session_id"] = session_id
        task.parameters = parameters
        event_context = {
            "task_id": str(task.id),
            "session_id": session_id,
            "prompt": task.prompt,
            "user_id": task.user_id,
            "config": req.config,
            "metadata": req.metadata,
            "parameters": task.parameters,
        }
        event = EventItem(
            event_type=EventType.TASK_PENDING,
            message="Enqueued task via MCP",
            context=event_context
        )
        db.session.add(event)
        db.session.commit()
        
        response = {
            "session_id": session_id,
            "output_dir_uri": output_dir_uri,
            "created_at": task.timestamp_created.isoformat() + "Z",
        }
    
    return CallToolResult(
        content=[TextContent(type="text", text=json.dumps(response))],
        structuredContent=response,
        isError=False,
    )

async def handle_session_start(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle planexe.session.start"""
    req = SessionStartRequest(**arguments)
    session_id = req.session_id
    
    with app.app_context():
        task = find_task_by_session_id(session_id)
        if task is None:
            return [TextContent(
                type="text",
                text=json.dumps({"error": {"code": "SESSION_NOT_FOUND", "message": f"Session not found: {session_id}"}})
            )]
        
        # Check if already running
        if task.state == TaskState.processing:
            return [TextContent(
                type="text",
                text=json.dumps({"error": {"code": "RUN_ALREADY_ACTIVE", "message": "A run is currently active for this session."}})
            )]
        
        # Update task to pending (worker_plan_database will pick it up and change to processing)
        task.state = TaskState.pending
        task.progress_percentage = 0.0
        task.progress_message = "Starting..."
        task.last_seen_timestamp = datetime.now(UTC)
        task.stop_requested = False
        task.stop_requested_timestamp = None

        db.session.commit()
        
        run_id = f"run_{str(task.id).replace('-', '_')}"
        response = {
            "run_id": run_id,
            "state": "running",
        }
    
    return [TextContent(type="text", text=json.dumps(response))]

async def handle_session_status(arguments: dict[str, Any]) -> CallToolResult:
    """Handle planexe.session.status"""
    req = SessionStatusRequest(**arguments)
    session_id = req.session_id
    
    with app.app_context():
        task = find_task_by_session_id(session_id)
        if task is None:
            response = {
                "error": {
                    "code": "SESSION_NOT_FOUND",
                    "message": f"Session not found: {session_id}",
                }
            }
            return CallToolResult(
                content=[TextContent(type="text", text=json.dumps(response))],
                structuredContent=response,
                isError=False,
            )
        
        # Determine phase based on progress
        progress_pct = float(task.progress_percentage) if task.progress_percentage else 0.0
        if progress_pct == 0.0:
            phase = "initializing"
        elif progress_pct < 50.0:
            phase = "generating_plan"
        elif progress_pct < 90.0:
            phase = "validating"
        elif progress_pct < 100.0:
            phase = "exporting"
        else:
            phase = "finalizing"
        
        run_id = f"run_{str(task.id).replace('-', '_')}"
        state = get_task_state_mapping(task.state)
        if task.state == TaskState.processing and task.stop_requested:
            state = "stopping"
        
        # Collect artifacts from worker_plan
        run_id = get_task_id_for_session(session_id)
        latest_artifacts = []
        if run_id:
            files_list = await fetch_file_list_from_worker_plan(run_id)
            if files_list:
                for file_name in files_list[:10]:  # Limit to 10 most recent
                    if file_name != "log.txt":
                        artifact_uri = f"planexe://sessions/{session_id}/out/{file_name}"
                        latest_artifacts.append({
                            "path": file_name,
                            "artifact_uri": artifact_uri,
                            "kind": "intermediate",
                            "updated_at": datetime.now(UTC).isoformat() + "Z",  # Approximate
                        })
        
        created_at = task.timestamp_created
        if created_at and created_at.tzinfo is None:
            created_at = created_at.replace(tzinfo=UTC)

        response = {
            "session_id": session_id,
            "run_id": run_id,
            "state": state,
            "phase": phase,
            "progress": {
                "overall": progress_pct / 100.0,
                "current_task": {
                    "name": task.progress_message or "Unknown",
                    "pct": progress_pct / 100.0,
                },
            },
            "timing": {
                "started_at": created_at.isoformat().replace("+00:00", "Z") if created_at else None,
                "elapsed_sec": (datetime.now(UTC) - created_at).total_seconds() if created_at else 0,
            },
            "latest_artifacts": latest_artifacts[:10],  # Limit to 10 most recent
            "warnings": [],
        }
    
    return CallToolResult(
        content=[TextContent(type="text", text=json.dumps(response))],
        structuredContent=response,
        isError=False,
    )

async def handle_session_stop(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle planexe.session.stop"""
    req = SessionStopRequest(**arguments)
    session_id = req.session_id
    
    with app.app_context():
        task = find_task_by_session_id(session_id)
        if task is None:
            return [TextContent(
                type="text",
                text=json.dumps({"error": {"code": "SESSION_NOT_FOUND", "message": f"Session not found: {session_id}"}})
            )]
        
        if task.state in (TaskState.pending, TaskState.processing):
            task.stop_requested = True
            task.stop_requested_timestamp = datetime.now(UTC)
            task.progress_message = "Stop requested by user."
            db.session.commit()
            logger.info("Stop requested for session %s; stop flag set on task %s.", session_id, task.id)
        
        response = {
            "state": "stopped",
        }
    
    return [TextContent(type="text", text=json.dumps(response))]

async def handle_session_resume(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle planexe.session.resume"""
    req = SessionResumeRequest(**arguments)
    session_id = req.session_id
    
    # Resume is similar to start - we create a new run (TaskItem state -> pending)
    # For now, we'll reuse the same task
    with app.app_context():
        task = find_task_by_session_id(session_id)
        if task is None:
            return [TextContent(
                type="text",
                text=json.dumps({"error": {"code": "SESSION_NOT_FOUND", "message": f"Session not found: {session_id}"}})
            )]
        
        if task.state == TaskState.processing:
            return [TextContent(
                type="text",
                text=json.dumps({"error": {"code": "RUN_ALREADY_ACTIVE", "message": "A run is currently active for this session."}})
            )]
        
        # Reset to pending to trigger a new run
        task.state = TaskState.pending
        task.progress_percentage = 0.0
        task.progress_message = "Resuming..."
        task.last_seen_timestamp = datetime.now(UTC)
        task.stop_requested = False
        task.stop_requested_timestamp = None
        db.session.commit()
        
        run_id = f"run_{str(task.id).replace('-', '_')}"
        response = {
            "run_id": run_id,
            "state": "running",
        }
    
    return [TextContent(type="text", text=json.dumps(response))]

async def handle_artifact_list(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle planexe.artifact.list"""
    req = ArtifactListRequest(**arguments)
    session_id = req.session_id
    
    run_id = get_task_id_for_session(session_id)
    if not run_id:
        return [TextContent(
            type="text",
            text=json.dumps({"error": {"code": "SESSION_NOT_FOUND", "message": f"Session not found: {session_id}"}})
        )]
    
    entries = []
    
    # Fetch file list from worker_plan
    files_list = await fetch_file_list_from_worker_plan(run_id)
    if files_list is None:
        # Return empty list if run doesn't exist yet
        response = {"entries": []}
        return [TextContent(type="text", text=json.dumps(response))]
    
    # Filter by path if specified
    if req.path:
        files_list = [f for f in files_list if f.startswith(req.path)]
    
    for file_name in files_list:
        # Skip log.txt as per spec
        if file_name == "log.txt":
            continue
        
        artifact_uri = f"planexe://sessions/{session_id}/out/{file_name}"
        
        # Guess content type from extension
        content_type = "application/octet-stream"
        if file_name.endswith(".md"):
            content_type = "text/markdown"
        elif file_name.endswith(".html"):
            content_type = "text/html"
        elif file_name.endswith(".json"):
            content_type = "application/json"
        elif file_name.endswith(".txt"):
            content_type = "text/plain"
        
        # For metadata, we'd need to fetch the file, but that's expensive
        # For now, return basic info without size/hash if metadata not required
        entry = {
            "type": "file",
            "path": file_name,
            "artifact_uri": artifact_uri,
            "content_type": content_type,
            "kind": "intermediate",
        }
        
        if req.include_metadata:
            # Fetch file to compute hash (expensive, but required by spec)
            content_bytes = await fetch_artifact_from_worker_plan(run_id, file_name)
            if content_bytes:
                entry["size"] = len(content_bytes)
                entry["sha256"] = compute_sha256(content_bytes)
                entry["updated_at"] = datetime.now(UTC).isoformat() + "Z"  # Approximate
            else:
                entry["size"] = 0
                entry["sha256"] = ""
                entry["updated_at"] = datetime.now(UTC).isoformat() + "Z"
        
        entries.append(entry)
    
    response = {"entries": entries}
    return [TextContent(type="text", text=json.dumps(response))]

async def handle_artifact_read(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle planexe.artifact.read"""
    req = ArtifactReadRequest(**arguments)
    artifact_uri = req.artifact_uri
    
    # Parse artifact_uri: planexe://sessions/{session_id}/out/{path}
    if not artifact_uri.startswith("planexe://sessions/"):
        return [TextContent(
            type="text",
            text=json.dumps({"error": {"code": "INVALID_ARTIFACT_URI", "message": f"Invalid artifact URI format: {artifact_uri}"}})
        )]
    
    parts = artifact_uri.replace("planexe://sessions/", "").split("/out/", 1)
    if len(parts) != 2:
        return [TextContent(
            type="text",
            text=json.dumps({"error": {"code": "INVALID_ARTIFACT_URI", "message": f"Invalid artifact URI format: {artifact_uri}"}})
        )]
    
    session_id = parts[0]
    artifact_path = parts[1]
    
    # Security: ensure path doesn't contain path traversal
    if ".." in artifact_path or "/" in artifact_path and artifact_path.startswith("/"):
        return [TextContent(
            type="text",
            text=json.dumps({"error": {"code": "PERMISSION_DENIED", "message": "Path traversal detected"}})
        )]
    
    run_id = get_task_id_for_session(session_id)
    if not run_id:
        return [TextContent(
            type="text",
            text=json.dumps({"error": {"code": "SESSION_NOT_FOUND", "message": f"Session not found: {session_id}"}})
        )]
    
    # Fetch artifact from worker_plan
    content_bytes = await fetch_artifact_from_worker_plan(run_id, artifact_path)
    if content_bytes is None:
        return [TextContent(
            type="text",
            text=json.dumps({"error": {"code": "INVALID_ARTIFACT_URI", "message": f"Artifact not found: {artifact_uri}"}})
        )]
    
    try:
        content_hash = compute_sha256(content_bytes)
        
        # Apply range if specified
        if req.range:
            start = req.range.get("start", 0)
            length = req.range.get("length", len(content_bytes))
            content_bytes = content_bytes[start:start+length]
        
        # Decode as text (try UTF-8, fallback to errors='replace')
        try:
            content = content_bytes.decode('utf-8')
            content_type = "text/plain"
            if artifact_path.endswith(".md"):
                content_type = "text/markdown"
            elif artifact_path.endswith(".html"):
                content_type = "text/html"
            elif artifact_path.endswith(".json"):
                content_type = "application/json"
        except UnicodeDecodeError:
            # Binary file, return base64 or indicate binary
            content = f"[Binary file, {len(content_bytes)} bytes]"
            content_type = "application/octet-stream"
        
        response = {
            "artifact_uri": artifact_uri,
            "content_type": content_type,
            "sha256": content_hash,
            "content": content,
        }
    except Exception as e:
        logger.error(f"Error processing artifact {artifact_uri}: {e}", exc_info=True)
        return [TextContent(
            type="text",
            text=json.dumps({"error": {"code": "INTERNAL_ERROR", "message": str(e)}})
        )]
    
    return [TextContent(type="text", text=json.dumps(response))]

async def handle_report_read(arguments: dict[str, Any]) -> CallToolResult:
    """Handle planexe.report.read / planexe.get.result."""
    req = ReportReadRequest(**arguments)
    session_id = req.session_id
    task = resolve_task_for_session(session_id)
    if task is None:
        response = {
            "error": {
                "code": "SESSION_NOT_FOUND",
                "message": f"Session not found: {session_id}",
            }
        }
        return CallToolResult(
            content=[TextContent(type="text", text=json.dumps(response))],
            structuredContent=response,
            isError=False,
        )

    if task.state in (TaskState.pending, TaskState.processing) or task.state is None:
        response = {"state": "running"}
        return CallToolResult(
            content=[TextContent(type="text", text=json.dumps(response))],
            structuredContent=response,
            isError=False,
        )
    if task.state == TaskState.failed:
        message = task.progress_message or "Plan generation failed."
        response = {"state": "failed", "error": {"code": "generation_failed", "message": message}}
        return CallToolResult(
            content=[TextContent(type="text", text=json.dumps(response))],
            structuredContent=response,
            isError=False,
        )

    run_id = str(task.id)
    content_bytes = await fetch_artifact_from_worker_plan(run_id, REPORT_FILENAME)
    if content_bytes is None:
        artifact_uri = build_report_artifact_uri(session_id)
        response = {
            "state": "failed",
            "error": {
                "code": "artifact_not_found",
                "message": f"Artifact not found: {artifact_uri}",
            },
        }
        return CallToolResult(
            content=[TextContent(type="text", text=json.dumps(response))],
            structuredContent=response,
            isError=False,
        )

    total_size = len(content_bytes)
    content_hash = compute_sha256(content_bytes)
    response = {
        "state": "ready",
        "artifact_uri": build_report_artifact_uri(session_id),
        "content_type": REPORT_CONTENT_TYPE,
        "sha256": content_hash,
        "download_path": build_report_download_path(session_id),
        "download_size": total_size,
    }
    download_url = build_report_download_url(session_id)
    if download_url:
        response["download_url"] = download_url

    if req.range is not None:
        range_request = req.range or {"start": 0, "length": REPORT_READ_DEFAULT_BYTES}
        start = max(int(range_request.get("start", 0)), 0)
        length_value = range_request.get("length")
        if length_value is None:
            length_value = REPORT_READ_DEFAULT_BYTES
        length = int(length_value)
        if length < 0:
            length = 0
        if length > REPORT_READ_MAX_BYTES:
            length = REPORT_READ_MAX_BYTES
        end = min(start + length, total_size)
        sliced_bytes = content_bytes[start:end]

        truncated = end < total_size
        response["content"] = sliced_bytes.decode("utf-8", errors="replace")
        response["total_size"] = total_size
        response["range"] = {"start": start, "length": len(sliced_bytes)}
        response["truncated"] = truncated
        if truncated:
            response["next_range"] = {"start": end, "length": min(length, total_size - end)}

    return CallToolResult(
        content=[TextContent(type="text", text=json.dumps(response))],
        structuredContent=response,
        isError=False,
    )

async def handle_artifact_write(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle planexe.artifact.write"""
    req = ArtifactWriteRequest(**arguments)
    artifact_uri = req.artifact_uri
    
    # Parse artifact_uri
    if not artifact_uri.startswith("planexe://sessions/"):
        return [TextContent(
            type="text",
            text=json.dumps({"error": {"code": "INVALID_ARTIFACT_URI", "message": f"Invalid artifact URI format: {artifact_uri}"}})
        )]
    
    parts = artifact_uri.replace("planexe://sessions/", "").split("/out/", 1)
    if len(parts) != 2:
        return [TextContent(
            type="text",
            text=json.dumps({"error": {"code": "INVALID_ARTIFACT_URI", "message": f"Invalid artifact URI format: {artifact_uri}"}})
        )]
    
    session_id = parts[0]
    artifact_path = parts[1]
    
    with app.app_context():
        # Check if session exists and is not running
        task = find_task_by_session_id(session_id)
        if task is None:
            return [TextContent(
                type="text",
                text=json.dumps({"error": {"code": "SESSION_NOT_FOUND", "message": f"Session not found: {session_id}"}})
            )]
        
        # Check if run is active (strict policy: reject writes while running)
        if task.state == TaskState.processing:
            return [TextContent(
                type="text",
                text=json.dumps({"error": {"code": "RUNNING_READONLY", "message": "Cannot write artifacts while run is active. Stop the run first."}})
            )]
        
        run_id = get_task_id_for_session(session_id)
        if not run_id:
            return [TextContent(
                type="text",
                text=json.dumps({"error": {"code": "SESSION_NOT_FOUND", "message": f"Session not found: {session_id}"}})
            )]
        
        # Security check: ensure path doesn't contain path traversal
        if ".." in artifact_path or "/" in artifact_path and artifact_path.startswith("/"):
            return [TextContent(
                type="text",
                text=json.dumps({"error": {"code": "PERMISSION_DENIED", "message": "Path traversal detected"}})
            )]
        
        # Optimistic locking check - fetch current file first
        if req.lock and req.lock.get("expected_sha256"):
            current_bytes = await fetch_artifact_from_worker_plan(run_id, artifact_path)
            if current_bytes:
                current_hash = compute_sha256(current_bytes)
                if current_hash != req.lock["expected_sha256"]:
                    return [TextContent(
                        type="text",
                        text=json.dumps({"error": {"code": "CONFLICT", "message": "SHA256 mismatch. Artifact was modified."}})
                    )]
        
        # Write file - for now, this is not supported via worker_plan HTTP API
        # We'd need to add a write endpoint to worker_plan, or use a different approach
        # For now, return an error indicating write is not yet supported via HTTP
        return [TextContent(
            type="text",
            text=json.dumps({"error": {"code": "NOT_IMPLEMENTED", "message": "Artifact write not yet supported via HTTP. Use database-backed approach or file system mount."}})
        )]
    
    return [TextContent(type="text", text=json.dumps(response))]

async def handle_session_events(arguments: dict[str, Any]) -> list[TextContent]:
    """Handle planexe.session.events"""
    req = SessionEventsRequest(**arguments)
    session_id = req.session_id
    
    with app.app_context():
        task = find_task_by_session_id(session_id)
        if task is None:
            return [TextContent(
                type="text",
                text=json.dumps({"error": {"code": "SESSION_NOT_FOUND", "message": f"Session not found: {session_id}"}})
            )]
        
        # Query events for this task
        since_id = int(req.since.replace("cursor_", "")) if req.since and req.since.startswith("cursor_") else 0
        
        events_query = db.session.query(EventItem).filter(
            EventItem.context.contains({"task_id": str(task.id)})
        ).filter(EventItem.id > since_id).order_by(EventItem.id.asc())
        
        events = events_query.all()
        
        event_list = []
        for event in events:
            event_type_map = {
                EventType.TASK_PROCESSING: "run_started",
                EventType.TASK_COMPLETED: "run_completed",
                EventType.TASK_FAILED: "run_failed",
                EventType.TASK_PENDING: "run_started",
            }
            
            mcp_event_type = event_type_map.get(event.event_type, "log")
            event_list.append({
                "ts": event.timestamp.isoformat() + "Z",
                "type": mcp_event_type,
                "data": event.context or {},
            })
        
        cursor = f"cursor_{events[-1].id}" if events else (req.since or "cursor_0")
        
        response = {
            "cursor": cursor,
            "events": event_list,
        }
    
    return [TextContent(type="text", text=json.dumps(response))]

async def main():
    """Main entry point for MCP server."""
    logger.info("Starting PlanExe MCP Server...")
    
    # Initialize database
    with app.app_context():
        db.create_all()
        logger.info("Database initialized")
    
    # Run MCP server over stdio
    async with stdio_server() as streams:
        await mcp_server.run(
            streams[0],
            streams[1],
            mcp_server.create_initialization_options()
        )

if __name__ == "__main__":
    asyncio.run(main())
